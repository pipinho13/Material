{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B/n Testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A/B/n testing** is an online technique used for comparing one **Control** to more versions of the original, with the purpose of determining the best performing one. The variants can be Subject Lines, Email Bodies, Web Pages, App Screens, Banners etc and the **KPI** can be the Open Rate, the Click Through Rate the Conversion Rate etc depending on company's objectives. Our goal is to give a brief view of A/B and A/B/n focusing mainly on R part without diving into maths details.\n",
    "\n",
    "### Confidence Intervals\n",
    "When we test a variant we get the observed \"Response Rate\" `p` which is just an estimate. Usually it is better to give a also the range of it by applying the Confidence Intervals.\n",
    "\n",
    "$$\\hat{p}\\pm Z_{\\frac{\\alpha}{2}}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$$\n",
    "\n",
    "where:  \n",
    "$\\hat{p}$: Response Rate of the variant.  \n",
    "$\\alpha$: The Level of Significance which is usally 5%.    \n",
    "$Z:$ The Standard Normal Distribution.    \n",
    "$n$: Is the sample size of the variant.  \n",
    "\n",
    "**Example**: Using R calculate the 95% Confidence Interval of the variant $V_1$ which has **150 Clicks** and **900 Impressions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.143746060287615</li>\n",
       "\t<li>0.192420704199088</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.143746060287615\n",
       "\\item 0.192420704199088\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.143746060287615\n",
       "2. 0.192420704199088\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.1437461 0.1924207\n",
       "attr(,\"conf.level\")\n",
       "[1] 0.95"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CI<-prop.test(x=150,n=900, correct = FALSE, conf.level = 0.95)\n",
    "CI$conf.int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing of One Variant\n",
    "\n",
    "As we saw above the observed CTR of the $V_1$ was 16.67% and let's assume that they asked us if the actual CTR of the $V_1$ could be 17%. In order to answer this type of questions we apply Hypothesis Testing of Proportion. In this example we apply the 2-sided tests. The Hypothesis can be written as:\n",
    "\n",
    "$$H_0: p=0.17$$\n",
    "$$H_1: p\\neq 0.17$$\n",
    "\n",
    "**Example**: Using R test if the actual $p$ of variant $V_1$ could be considered as **0.17** and then test again for **0.20**\n",
    "\n",
    "**Hypothesis Testing for p=0.17**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\t1-sample proportions test without continuity correction\n",
       "\n",
       "data:  150 out of 900, null probability 0.17\n",
       "X-squared = 0.070872, df = 1, p-value = 0.7901\n",
       "alternative hypothesis: true p is not equal to 0.17\n",
       "95 percent confidence interval:\n",
       " 0.1437461 0.1924207\n",
       "sample estimates:\n",
       "        p \n",
       "0.1666667 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1<-prop.test(x=150,n=900, p=0.17, alternative = c(\"two.sided\"), conf.level = 0.95, correct = FALSE)\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis Testing for p=0.20**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\t1-sample proportions test without continuity correction\n",
       "\n",
       "data:  150 out of 900, null probability 0.2\n",
       "X-squared = 6.25, df = 1, p-value = 0.01242\n",
       "alternative hypothesis: true p is not equal to 0.2\n",
       "95 percent confidence interval:\n",
       " 0.1437461 0.1924207\n",
       "sample estimates:\n",
       "        p \n",
       "0.1666667 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t2<-prop.test(x=150,n=900, p=0.20, correct = FALSE)\n",
    "t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reject the **Null Hypothesis** we want the p-value to be less than the level of significance $\\alpha$ which is usually 5%. In our case we did not reject the Null Hypothesis for p=17% (p-value=0.79) but we rejected for p=20% (p-value=0.012)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing of Two Variants\n",
    "We can apply the Z-Tet of proportions when we want to compare two variants about their Response Rates. Without going into details we represent the formula of the Z standard Normal of the difference of two binomial distributions.\n",
    "\n",
    "$$Z=\\frac{\\hat{p_1}-{\\hat{p_2}}}{\\sqrt{\\hat{p}(1-\\hat{p})(\\frac{1}{n1}+\\frac{1}{n2})}}$$\n",
    "where $\\hat{p}=\\frac{x_1+x_2}{n_1+n_2}$ is the average of the Response Rate of the two variants.  \n",
    "The Hypothesis can be formulated as:\n",
    "\n",
    "$$H_0: p_1=p_2$$\n",
    "$$H_1: p_1\\neq p_2$$\n",
    "\n",
    "**Example**: Using R calculate compare the variant $V_1$ which has **120 Clicks and 800 Impressions** with variant $V_2$ which has **100 Clicks and 700 Impressions** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\t2-sample test for equality of proportions without continuity\n",
       "\tcorrection\n",
       "\n",
       "data:  x out of n\n",
       "X-squared = 0.15219, df = 1, p-value = 0.6964\n",
       "alternative hypothesis: two.sided\n",
       "95 percent confidence interval:\n",
       " -0.02869299  0.04297870\n",
       "sample estimates:\n",
       "   prop 1    prop 2 \n",
       "0.1500000 0.1428571 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define a vector of the responses\n",
    "x<-c(120,100)\n",
    "# define a vector of the impressions\n",
    "n<-c(800,700)\n",
    "test1<-prop.test(x,n, correct = FALSE)\n",
    "test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: The z-test comparing two proportions is equivalent to the chi-square test of independence, and the prop.test( ) procedure formally calculates the chi-square test. The p-value from the z-test for two proportions is equal to the p-value from the chi-square test, and the z-statistic is equal to the square root of the chi-square statistic in this situation.  \n",
    "As we can see  R provides as a nice output which shows the proportion of each variant as well as the p-value. In our case we do not reject the null hypothesis since the p-value (0.6964) is greater than 5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing of k Variants\n",
    "In most cases we test more than two variants and someone can ask if all of these variants can be considered as equivalent or not (i.e. if they their responses rates (RR) are equivalent).  \n",
    "In order to answer this question we can apply the **Chi-Square Test** $\\chi^2$.  \n",
    "The Null and the Alternative hypothesis can be written as:  \n",
    "\n",
    "$$H_0: p_1=p_2=...=p_K$$\n",
    "$$H_1: The~RRs~Are~Not~All~Equal$$\n",
    "\n",
    "**Example**: Assume that we have 8 variants with the following clicks (80,85,90,95,100,105,110,115) respectively and all of them have 1000 impressions. Using R determine if all these variants can be considered equivalent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\t8-sample test for equality of proportions without continuity\n",
       "\tcorrection\n",
       "\n",
       "data:  x out of n\n",
       "X-squared = 11.933, df = 7, p-value = 0.1028\n",
       "alternative hypothesis: two.sided\n",
       "sample estimates:\n",
       "prop 1 prop 2 prop 3 prop 4 prop 5 prop 6 prop 7 prop 8 \n",
       " 0.080  0.085  0.090  0.095  0.100  0.105  0.110  0.115 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x<-seq(from=80, by=5, length.out=8)\n",
    "n<-rep(1000,8)\n",
    "chisqtest<-prop.test(x,n)\n",
    "chisqtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As see we can consider all these 8 variants as equivalent (p-value: 0.1028) . However if we compare just the first one with the last one it comes out their difference is statistically significant. This is due to the effect of \"Multiple Comparisons\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Pairwise Comparisons Without P-Value Adjustments\n",
    "Using R we can easily represent the P-values of all pairwise comparisons. Let's do it using the data of the above example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tPairwise comparisons using Pairwise comparison of proportions \n",
       "\n",
       "data:  x out of n \n",
       "\n",
       "  1     2     3     4     5     6     7    \n",
       "2 0.745 -     -     -     -     -     -    \n",
       "3 0.471 0.752 -     -     -     -     -    \n",
       "4 0.268 0.482 0.758 -     -     -     -    \n",
       "5 0.138 0.280 0.492 0.763 -     -     -    \n",
       "6 0.064 0.147 0.291 0.502 0.768 -     -    \n",
       "7 0.027 0.070 0.157 0.302 0.512 0.773 -    \n",
       "8 0.010 0.031 0.077 0.166 0.312 0.520 0.777\n",
       "\n",
       "P value adjustment method: none "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x<-seq(from=80, by=5, length.out=8)\n",
    "n<-rep(1000,8)\n",
    "ppt<-pairwise.prop.test(x, n, p.adjust.method = \"none\")\n",
    "ppt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Pairwise Comparisons With P-Value Adjustments\n",
    "\n",
    "Since we are dealing with Multiple Comparisons it is common to apply the p-value adjustments. R provides us the following methods of p-value adjustments.\n",
    "\n",
    "{\"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\",  \"fdr\", \"none\"}\n",
    "\n",
    "Let's apply the above example using the **False Discovery Rate** as method of adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tPairwise comparisons using Pairwise comparison of proportions \n",
       "\n",
       "data:  x out of n \n",
       "\n",
       "  1    2    3    4    5    6    7   \n",
       "2 0.78 -    -    -    -    -    -   \n",
       "3 0.69 0.78 -    -    -    -    -   \n",
       "4 0.58 0.69 0.78 -    -    -    -   \n",
       "5 0.46 0.58 0.69 0.78 -    -    -   \n",
       "6 0.36 0.46 0.58 0.69 0.78 -    -   \n",
       "7 0.29 0.36 0.46 0.58 0.69 0.78 -   \n",
       "8 0.29 0.29 0.36 0.46 0.58 0.69 0.78\n",
       "\n",
       "P value adjustment method: fdr "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x<-seq(from=80, by=5, length.out=8)\n",
    "n<-rep(1000,8)\n",
    "ppt<-pairwise.prop.test(x, n, p.adjust.method = \"fdr\")\n",
    "ppt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see now, none of the pairs can be considered as statistically significant different.\n",
    "\n",
    "### Multiple Pairwise Comparisons of Control Variant With P-Value Adjustments\n",
    "Sometimes we want to compare only the Control versus the rest variants. In this case we need to take the p-values of the Control vs the rest variants using none adjustment and then to apply the p-value adjustments.  \n",
    "Again let's use the same data and assuming that the Control is the $V_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>2</dt>\n",
       "\t\t<dd>0.745106514499674</dd>\n",
       "\t<dt>3</dt>\n",
       "\t\t<dd>0.470529222181811</dd>\n",
       "\t<dt>4</dt>\n",
       "\t\t<dd>0.267913806724692</dd>\n",
       "\t<dt>5</dt>\n",
       "\t\t<dd>0.137661417058499</dd>\n",
       "\t<dt>6</dt>\n",
       "\t\t<dd>0.0639884277532946</dd>\n",
       "\t<dt>7</dt>\n",
       "\t\t<dd>0.0269977223121986</dd>\n",
       "\t<dt>8</dt>\n",
       "\t\t<dd>0.0103790747184265</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[2] 0.745106514499674\n",
       "\\item[3] 0.470529222181811\n",
       "\\item[4] 0.267913806724692\n",
       "\\item[5] 0.137661417058499\n",
       "\\item[6] 0.0639884277532946\n",
       "\\item[7] 0.0269977223121986\n",
       "\\item[8] 0.0103790747184265\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "2\n",
       ":   0.7451065144996743\n",
       ":   0.4705292221818114\n",
       ":   0.2679138067246925\n",
       ":   0.1376614170584996\n",
       ":   0.06398842775329467\n",
       ":   0.02699772231219868\n",
       ":   0.0103790747184265\n",
       "\n"
      ],
      "text/plain": [
       "         2          3          4          5          6          7          8 \n",
       "0.74510651 0.47052922 0.26791381 0.13766142 0.06398843 0.02699772 0.01037907 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x<-seq(from=80, by=5, length.out=8)\n",
    "n<-rep(1000,8)\n",
    "ppt<-pairwise.prop.test(x, n, p.adjust.method = \"none\")\n",
    "# this vector is the p-values of variant 1 versus the rest 7 variants without adjustments\n",
    "pvalue_vector<-ppt$p.value[,1]\n",
    "pvalue_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>2</dt>\n",
       "\t\t<dd>0.745106514499674</dd>\n",
       "\t<dt>3</dt>\n",
       "\t\t<dd>0.548950759212113</dd>\n",
       "\t<dt>4</dt>\n",
       "\t\t<dd>0.375079329414569</dd>\n",
       "\t<dt>5</dt>\n",
       "\t\t<dd>0.240907479852373</dd>\n",
       "\t<dt>6</dt>\n",
       "\t\t<dd>0.149306331424354</dd>\n",
       "\t<dt>7</dt>\n",
       "\t\t<dd>0.0944920280926952</dd>\n",
       "\t<dt>8</dt>\n",
       "\t\t<dd>0.0726535230289856</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[2] 0.745106514499674\n",
       "\\item[3] 0.548950759212113\n",
       "\\item[4] 0.375079329414569\n",
       "\\item[5] 0.240907479852373\n",
       "\\item[6] 0.149306331424354\n",
       "\\item[7] 0.0944920280926952\n",
       "\\item[8] 0.0726535230289856\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "2\n",
       ":   0.7451065144996743\n",
       ":   0.5489507592121134\n",
       ":   0.3750793294145695\n",
       ":   0.2409074798523736\n",
       ":   0.1493063314243547\n",
       ":   0.09449202809269528\n",
       ":   0.0726535230289856\n",
       "\n"
      ],
      "text/plain": [
       "         2          3          4          5          6          7          8 \n",
       "0.74510651 0.54895076 0.37507933 0.24090748 0.14930633 0.09449203 0.07265352 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now apply the pvalue adjustment to the vector of pvalues\n",
    "p.adjust(pvalue_vector, method = \"fdr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Comparisons applying TukeyHSD Test\n",
    "We can also run a Logistic Regression applying the **Tukey Test**. Let's apply it  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>x</th><th scope=col>n</th><th scope=col>ID</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 80 </td><td>1000</td><td>1   </td></tr>\n",
       "\t<tr><td> 85 </td><td>1000</td><td>2   </td></tr>\n",
       "\t<tr><td> 90 </td><td>1000</td><td>3   </td></tr>\n",
       "\t<tr><td> 95 </td><td>1000</td><td>4   </td></tr>\n",
       "\t<tr><td>100 </td><td>1000</td><td>5   </td></tr>\n",
       "\t<tr><td>105 </td><td>1000</td><td>6   </td></tr>\n",
       "\t<tr><td>110 </td><td>1000</td><td>7   </td></tr>\n",
       "\t<tr><td>115 </td><td>1000</td><td>8   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " x & n & ID\\\\\n",
       "\\hline\n",
       "\t  80  & 1000 & 1   \\\\\n",
       "\t  85  & 1000 & 2   \\\\\n",
       "\t  90  & 1000 & 3   \\\\\n",
       "\t  95  & 1000 & 4   \\\\\n",
       "\t 100  & 1000 & 5   \\\\\n",
       "\t 105  & 1000 & 6   \\\\\n",
       "\t 110  & 1000 & 7   \\\\\n",
       "\t 115  & 1000 & 8   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| x | n | ID |\n",
       "|---|---|---|\n",
       "|  80  | 1000 | 1    |\n",
       "|  85  | 1000 | 2    |\n",
       "|  90  | 1000 | 3    |\n",
       "|  95  | 1000 | 4    |\n",
       "| 100  | 1000 | 5    |\n",
       "| 105  | 1000 | 6    |\n",
       "| 110  | 1000 | 7    |\n",
       "| 115  | 1000 | 8    |\n",
       "\n"
      ],
      "text/plain": [
       "  x   n    ID\n",
       "1  80 1000 1 \n",
       "2  85 1000 2 \n",
       "3  90 1000 3 \n",
       "4  95 1000 4 \n",
       "5 100 1000 5 \n",
       "6 105 1000 6 \n",
       "7 110 1000 7 \n",
       "8 115 1000 8 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in RET$pfunction(\"adjusted\", ...):\n",
      "\"Completion with error > abseps\"Warning message in RET$pfunction(\"adjusted\", ...):\n",
      "\"Completion with error > abseps\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\t Simultaneous Tests for General Linear Hypotheses\n",
       "\n",
       "Multiple Comparisons of Means: Tukey Contrasts\n",
       "\n",
       "\n",
       "Fit: glm(formula = cbind(x, n - x) ~ ID, family = binomial(link = \"logit\"), \n",
       "    data = dataset)\n",
       "\n",
       "Linear Hypotheses:\n",
       "           Estimate Std. Error z value Pr(>|z|)\n",
       "2 - 1 == 0  0.06607    0.16262   0.406    1.000\n",
       "3 - 1 == 0  0.12871    0.16061   0.801    0.993\n",
       "4 - 1 == 0  0.18829    0.15880   1.186    0.936\n",
       "5 - 1 == 0  0.24512    0.15716   1.560    0.774\n",
       "6 - 1 == 0  0.29948    0.15565   1.924    0.534\n",
       "7 - 1 == 0  0.35161    0.15428   2.279    0.306\n",
       "8 - 1 == 0  0.40169    0.15301   2.625    0.146\n",
       "3 - 2 == 0  0.06264    0.15833   0.396    1.000\n",
       "4 - 2 == 0  0.12221    0.15649   0.781    0.994\n",
       "5 - 2 == 0  0.17905    0.15482   1.157    0.944\n",
       "6 - 2 == 0  0.23341    0.15329   1.523    0.795\n",
       "7 - 2 == 0  0.28553    0.15190   1.880    0.564\n",
       "8 - 2 == 0  0.33562    0.15061   2.228    0.334\n",
       "4 - 3 == 0  0.05958    0.15441   0.386    1.000\n",
       "5 - 3 == 0  0.11641    0.15271   0.762    0.995\n",
       "6 - 3 == 0  0.17077    0.15117   1.130    0.950\n",
       "7 - 3 == 0  0.22289    0.14975   1.488    0.814\n",
       "8 - 3 == 0  0.27298    0.14844   1.839    0.593\n",
       "5 - 4 == 0  0.05683    0.15081   0.377    1.000\n",
       "6 - 4 == 0  0.11119    0.14924   0.745    0.996\n",
       "7 - 4 == 0  0.16332    0.14780   1.105    0.956\n",
       "8 - 4 == 0  0.21340    0.14648   1.457    0.830\n",
       "6 - 5 == 0  0.05436    0.14749   0.369    1.000\n",
       "7 - 5 == 0  0.10648    0.14603   0.729    0.996\n",
       "8 - 5 == 0  0.15657    0.14470   1.082    0.961\n",
       "7 - 6 == 0  0.05212    0.14441   0.361    1.000\n",
       "8 - 6 == 0  0.10221    0.14306   0.714    0.997\n",
       "8 - 7 == 0  0.05009    0.14156   0.354    1.000\n",
       "(Adjusted p values reported -- single-step method)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(multcomp)\n",
    "\n",
    "dataset<-data.frame(x=seq(from=80, by=5, length.out=8), n=rep(1000,8), ID=factor(c(1:8)))\n",
    "dataset\n",
    "model1<- glm(formula = cbind(x, n-x) ~ ID, family = binomial(link = \"logit\"), data=dataset)\n",
    "\n",
    "# Tukey multiple comparisons\n",
    "summary(glht(model1, mcp(ID=\"Tukey\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
